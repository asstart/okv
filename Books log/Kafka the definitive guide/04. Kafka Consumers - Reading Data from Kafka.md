---

title: 04. Kafka Consumers - Reading Data from Kafka
layout: default
parent: Kafka the definitive guide
grand_parent: Books log

---

## Consumers and Consumer Groups

![Pasted image 20230214170917.png](/Books%20log/Kafka%20the%20definitive%20guide/img/Pasted%20image%2020230214170917.png)

Kafka consumers are typically part of a consumer group. When multiple consumers are subscribed to a topic and belong to the same consumer group, each consumer in the group will receive messages from a different subset of the partitions in the topic.

The main way we scale data consumption from a Kafka topic is by adding more consumers to a consumer group.

It is very common to have multiple applications that need to read data from the same topic. In those cases, we want each application to get all of the messages, rather than just a subset. To make sure an application gets all the messages in a topic, ensure the application has its own consumer group

## Consumer Groups and Partition Rebalance

When we add a new consumer to the group, it starts consuming messages from partitions previously consumed by another consumer. The same thing happens when a consumer shuts down or crashes; it leaves the group, and the partitions it used to consume will be consumed by one of the remaining consumers. This process of moving partition's ownership from one consumer to another is called *rebalance*.

There are 2 types of rebalances:

1.  Eager - during this rebalance, all consumers stop consuming, give up their ownership of all partitions, rejoin the consumer group, and get a brand-new partition assignment.
    ![Pasted image 20230214171847.png](/Books%20log/Kafka%20the%20definitive%20guide/img/Pasted%20image%2020230214171847.png)
2.  Cooperative (incremental) - typically involve reassigning only a small subset of the partitions from one consumer to another. Consists of 2 or more phases:
    1.  Consumer group leader informs all the consumers that they will lose ownership of a subset of their partitions, then the consumers stop consuming from these partitions and give up their ownership in them.
    2.  Consumer group leader assigns these now orphaned partitions to their new owners.

> This incremental approach may take a few iterations until a stable partition assignment is achieved, but it avoids the complete “stop the world”

![Pasted image 20230214172209.png](/Books%20log/Kafka%20the%20definitive%20guide/img/Pasted%20image%2020230214172209.png)

Consumers maintain membership in a consumer group and ownership of the partitions assigned to them by sending heartbeats to a Kafka broker designated as the group coordinator.

## Static Group Membership

By default, the identity of a consumer as a member of its consumer group is transient. When consumers leave a consumer group, the partitions that were assigned to the consumer are revoked, and when it rejoins, it is assigned a new member ID and a new set of partitions through the rebalance protocol.

If you configure consumer with a unique `group.instance.id` it will become *static member of the group*. If this consumer is shutdown, its partitions won't be revoked and after rejoin it will be able to continue to handle messages from its partitions. But also it means, if consumer is shutdown this partition won't be reassigned to other consumer and will stay unhandled. Detecting if static consumer really gone depends on `session.timeout.ms` parameter.

## Consumer Basic Ops

### Creating

```java
Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092,broker2:9092");
props.put("group.id", "CountryCounter");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);
```

### Subscribing to Topic

```java
consumer.subscribe(Collections.singletonList("customerCountries"));
```

Also, you can subscribe on multiple topics by providing regexp. But it may significantly affect network, client and broker in case having a big number of topics and partitions. It will request in regular interval list of topics and their partitions.

```java
consumer.subscribe(Pattern.compile("test.*"));
```

### Poll Loop

```java
Duration timeout = Duration.ofMillis(100);
while (true) {
	ConsumerRecords<String, String> records = consumer.poll(timeout);
	for (ConsumerRecord<String, String> record : records) {
		System.out.printf("topic = %s, partition = %d, offset = %d, " +"customer = %s, country = %s\n",
		record.topic(), record.partition(), record.offset(), record.key(), record.value());
		int updatedCount = 1;
		if (custCountryMap.containsKey(record.value())) {
			updatedCount = custCountryMap.get(record.value()) + 1;
		}
		custCountryMap.put(record.value(), updatedCount);
		JSONObject json = new JSONObject(custCountryMap);
		System.out.println(json.toString());
	}
}
```

During the first call of `poll()` the `GroupCoordinator` will be found, consumer will join to consumer group and get partitions list.

`timeout` parameter of `poll()` is responsible for how long request will be blocked if no messages in the broker. 0 refers to return response immediately.

`max.poll.interval.ms` - define how long messages can be handled between polls until consumer marked dead.

### Gracefully Shutdown Poll Loop

When you decide to shut down the consumer, and you want to exit immediately even though the consumer may be waiting on a long `poll()`, you will need another thread to call `consumer.wakeup()`. Calling wake-up will cause `poll()` to exit with [`WakeupException`](https://kafka.apache.org/24/javadoc/index.html?org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html), or if `consumer.wakeup()` was called while the thread was not waiting on poll, the exception will be thrown on the next iteration when `poll()` is called. The `WakeupException` doesn’t need to be handled, but before exiting the thread, you must call `consumer.close()`.

```java
Runtime.getRuntime().addShutdownHook(new Thread() {
	public void run() {
		System.out.println("Starting exit...");
		consumer.wakeup();
		try {
			mainThread.join();
		} catch (InterruptedException e) {
			e.printStackTrace();
		}

	} 
});

Duration timeout = Duration.ofMillis(10000);

try {
	// looping until ctrl-c, the shutdown hook will cleanup on exit
	while (true) {
		ConsumerRecords<String, String> records = movingAvg.consumer.poll(timeout);
		System.out.println(System.currentTimeMillis() + "--  waiting for data...");
		for (ConsumerRecord<String, String> record : records) {
			System.out.printf("offset = %d, key = %s, value = %s\n", record.offset(), record.key(), record.value());
        }
        for (TopicPartition tp: consumer.assignment())
            System.out.println("Committing offset at position: consumer.position(tp)");
            movingAvg.consumer.commitSync();
        }
} catch (WakeupException e) {
    // ignore for shutdown
} finally {
    consumer.close();
    System.out.println("Closed consumer and we are done");
}
```

## Thread Safety

One consumer per thread is the rule.

## Configuring Consumers

*   `fetch.min.bytes` - minimum amount of data that consumer wants to receive from the broker when fetching records, **by default one byte**. If broker has data less than value of `fetch.min.bytes` request will be blocked until required amount of bytes will become available
*   `fetch.max.wait.ms` - configure how long request will be blocked during waiting required amount of bytes set by `fetch.min.bytes`. By default, it's 500ms
*   `fetch.max.bytes` - the maximum bytes that Kafka will return whenever the consumer polls a broker. By default, is 50MB
*   `max.poll.records` - the maximum number of records that a single call to `poll()` will return
*   `max.partition.fetch.bytes` - the maximum number of bytes the server will return per partition By default, 1 MB. It's better to `fetch.max.bytes` instead this.
*   `heartbeat.interval.ms` - how often consumer send *heartbeat* to the broker.
*   `session.timeout.ms` - the amount of time a broker can be out of contact with a consumer while still considering it's alive. By default, 10s. Typically, should be x3 of `heartbeat.interval.ms`
*   `max.poll.interval.ms` - time during which the consumer can go without polling before it is considered dead
*   `default.api.timeout.ms` - the timeout that will apply to (almost) all API calls made by the consumer when you don’t specify an explicit timeout while calling the API
*   `request.timeout.ms` - the maximum amount of time the consumer will wait for a response from the broker. By default, 30s. If the broker does not respond within this time, the client will assume the broker will not respond at all, close the connection, and attempt to reconnect
*   `auto.offset.reset` -
*   `enable.auto.commit` - controls whether the consumer will commit offsets automatically. By default, `true`
*   `partition.assignment.strategy`
    *   Range (default) - assigns to each consumer a consecutive subset of partitions from each topic it subscribes to
    *   RoundRobin - takes all the partitions from all subscribed topics and assigns them to consumers sequentially, one by one
    *   Sticky - sticky Assignor has two goals: the first is to have an assignment that is as balanced as possible, and the second is that in case of a rebalance, it will leave as many assignments as possible in place, minimizing the overhead associated with moving partition assignments from one consumer to another
    *   Cooperative Sticky - strategy is identical to that of the Sticky Assignor but supports cooperative rebalances in which consumers can continue consuming from the partitions that are not reassigned
*   `client.id` - any string that will be used by the brokers to identify requests sent from the client, such as fetch requests. It is used in logging and metrics, and for quotas
*   `client.rack` - enable fetching from the closest replica in case of multi datacenter or multicloud deploy. Broker also must be configured to use `replica.selector.class` with `org.apache.kafka.common.replica.Rack AwareReplicaSelector`
*   `group.instance.id` - any unique string is used to provide a consumer with static group membership

## Commits and Offsets

### Auto commit

If `enable.auto.commit=true`, then every **five seconds** (by default) the consumer will commit the latest offset that your client received from `poll()`. This interval can be configured by setting `auto.commit.interval.ms`.
Auto commit might be a cause of handling a list of records twice in case of rebalancing.
With auto commit enabled, when it is time to commit offsets, the next poll will commit the last offset returned by the previous poll.

### Commit Current Offset

By setting `enable.auto.commit=false`, offsets will only be committed when the application explicitly chooses to do so. By calling `commitSync()` app will commit the latest offset returned by `poll()` no matter if it already handled or not, so it's important to understand when to commit otherwise messages might be lost.

Recommend approach for manual commit:

```java
Duration timeout = Duration.ofMillis(100);

while (true) {
	ConsumerRecords<String, String> records = consumer.poll(timeout);
	for (ConsumerRecord<String, String> record : records) {
		System.out.printf("topic = %s, partition = %d, offset = %d, customer = %s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());
	} try { 
		consumer.commitSync();
	} catch (CommitFailedException e) {
		log.error("commit failed", e)
	}
}
```

### Asynchronous Commit

In case of using `commitSync()`, the application is blocked until the broker responds to the commit request. Another option to use `commitAsync()` but it's to remember that unlike `commitSync()` it won't try to retry in case of error because it might be broke order of commits due to it async nature. It also can have a callback function, but it also shouldn't be used to retry commit, only to log error or something similar.

Recommend approach for manual async commit:

```java
Duration timeout = Duration.ofMillis(100);

while (true) {
	ConsumerRecords<String, String> records = consumer.poll(timeout);
	for (ConsumerRecord<String, String> record : records) {
		System.out.printf("topic = %s, partition = %s, offset = %d, customer = %s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());
}

consumer.commitAsync(new OffsetCommitCallback() {
	public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception e) {
		if (e != null)
			log.error("Commit failed for offsets {}", offsets, e);
		}
	});
}
```

### Combining Synchronous and Asynchronous Commits

A common pattern is to combine `commitAsync()` with `commitSync()` just before shutdown:

```java
Duration timeout = Duration.ofMillis(100);

try {
	while (!closing) {
		ConsumerRecords<String, String> records = consumer.poll(timeout);
		for (ConsumerRecord<String, String> record : records) {
			System.out.printf("topic = %s, partition = %s, offset = %d, customer = %s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());
		}
		consumer.commitAsync();
	}
	consumer.commitSync();
} catch (Exception e) {
	log.error("Unexpected error", e);
} finally {
	consumer.close(); 
}
```

### Committing a Specified Offset

In case you need to commit more frequently, commit of specified offset can be used.

```java
private Map<TopicPartition, OffsetAndMetadata> currentOffsets =
	new HashMap<>();

int count = 0;

Duration timeout = Duration.ofMillis(100);

while (true) {
	ConsumerRecords<String, String> records = consumer.poll(timeout);
	for (ConsumerRecord<String, String> record : records) {
		System.out.printf("topic = %s, partition = %s, offset = %d, customer = %s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());

		currentOffsets.put(
			new TopicPartition(record.topic(), record.partition()),
			new OffsetAndMetadata(record.offset()+1, "no metadata")
		);
			
		if (count % 1000 == 0) {
			consumer.commitAsync(currentOffsets, null);
		}
		count++; 
	}
}
```

## Rebalance Listeners

If some work must be done before rebalancing or before partition assignment, [ConsumerRebalance Listener](https://kafka.apache.org/24/javadoc/index.html?org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html) need to be implemented and passed to `subscribe()`

```java
private Map<TopicPartition, OffsetAndMetadata> currentOffsets = new HashMap<>();

Duration timeout = Duration.ofMillis(100);

private class HandleRebalance implements ConsumerRebalanceListener {
	public void onPartitionsAssigned(Collection<TopicPartition> partitions) {}

	public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
		System.out.println("Lost partitions in rebalance. Committing current offsets:" + currentOffsets);
		consumer.commitSync(currentOffsets);
	} 
}

try {
	consumer.subscribe(topics, new HandleRebalance());

	while (true) {
		ConsumerRecords<String, String> records = consumer.poll(timeout);
		for (ConsumerRecord<String, String> record : records) {
			System.out.printf("topic = %s, partition = %s, offset = %d, customer = %s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());	
			 currentOffsets.put(
				 new TopicPartition(record.topic(), record.partition()),
				 new OffsetAndMetadata(record.offset()+1, null)
			);
		}
		consumer.commitAsync(currentOffsets, null);
	}
} catch (WakeupException e) {
// ignore, we're closing
} catch (Exception e) {
	log.error("Unexpected error", e);
} finally {
	try {
		consumer.commitSync(currentOffsets);
	} finally {
		consumer.close();
		System.out.println("Closed consumer and we are done");
	}
}
```

*   `onPartitionsAssigned(Collection<TopicPartition> partitions)` - will be invoked on every rebalance. If there are no new partitions assigned, `partitions` collection will be empty
*   `onPartitionsRevoked(Collection<TopicPartition> partitions)` - will be invoked in normal rebalancing conditions, but only if consumer give up the ownership of partitions
*   `onPartitionsLost(Collection<TopicPartition> partitions)` - will be invoked in exceptional rebalancing conditions, and the partitions in the collection will already have new owners by the time the method is invoked

## Consuming Records with Specific Offsets

There are plenty of methods to start consuming from a specific point:

*   `seek(TopicPartition partition, long offset)` and `seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata)` - overrides the fetch offsets that the consumer will use on the next [`poll(timeout)`](https://kafka.apache.org/24/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#poll-java.time.Duration-)
*   `seekToBeginning(Collection<TopicPartition> partitions)` - seek to the first offset for each of the given partitions
*   `seekToEnd(Collection<TopicPartition> partitions)` - seek to the last offset for each of the given partitions
    But it's better to look at [documentation](https://kafka.apache.org/24/javadoc/index.html?org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html) to learn this.

## Deserializers

The opposite for serializers in [Producers](03.%20Kafka%20Producers%20-%20Writing%20Messages%20to%20Kafka%20) - require to convert byte arrays received from Kafka into Java objects.

## Standalone Consumer: Why and How to Use a Consumer Without a Group

When you know exactly which partitions the consumer should read, you don’t subscribe to a topic - instead, you assign yourself a few partitions. A consumer can either subscribe to topics (and be part of a consumer group) or assign itself partitions, but not both at the same time.

```java
Duration timeout = Duration.ofMillis(100);
List<PartitionInfo> partitionInfos = null;
partitionInfos = consumer.partitionsFor("topic");

if (partitionInfos != null) {
	for (PartitionInfo partition : partitionInfos)
		partitions.add(
			new TopicPartition(
				partition.topic(),
				partition.partition()
				)
			);
	consumer.assign(partitions);
	
	while (true) {
		ConsumerRecords<String, String> records = consumer.poll(timeout);
		for (ConsumerRecord<String, String> record: records) {
			System.out.printf("topic = %s, partition = %s, offset = %d, customer = %s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());
		}
		consumer.commitSync();
	}
}
```
