---

title: 05. Managing Apache Kafka Programmatically
layout: default
parent: Kafka the definitive guide
grand_parent: Books log

---

## Overview

[Kafka Admin Package](https://kafka.apache.org/30/javadoc/org/apache/kafka/clients/admin/package-summary.html)
[Admin interface](https://kafka.apache.org/30/javadoc/org/apache/kafka/clients/admin/Admin.html)
[KafkaAdminClient](https://kafka.apache.org/30/javadoc/org/apache/kafka/clients/admin/KafkaAdminClient.html)

1.  Kafka Admin API is fully asynchronous
2.  All methods implemented in [KafkaAdminClient](https://kafka.apache.org/30/javadoc/org/apache/kafka/clients/admin/KafkaAdminClient.html) - no complex class hierarchy
3.  Every API method has `timeoutMs` to control how long client will wait response before throw `TimeoutException`

## Admin Client Ops

### Create Client

```java
Properties props = new Properties();
props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
AdminClient admin = AdminClient.create(props);
// TODO: Do something useful with AdminClient
admin.close(Duration.ofSeconds(30))
```

### Mange Topic

List all topics:

```java
ListTopicsResult topics = admin.listTopics();
topics.names().get().forEach(System.out::println)
```

Check if a topic exists, and create it if it doesnâ€™t:

```java
scribeTopicsResult demoTopic = admin.describeTopics(TOPIC_LIST);

try {
	topicDescription = demoTopic.values().get(TOPIC_NAME).get();
	System.out.println("Description of demo topic:" + topicDescription);

	if (topicDescription.partitions().size() != NUM_PARTITIONS) {
	  System.out.println("Topic has wrong number of partitions. Exiting.");
	  System.exit(-1);
	}
	
} catch (ExecutionException e) {
	// exit early for almost all exceptions
	if (! (e.getCause() instanceof UnknownTopicOrPartitionException)) {
		e.printStackTrace();
		throw e; 
	}
	// if we are here, topic doesn't exist
	System.out.println("Topic " + TOPIC_NAME + " does not exist. Going to create it now");
	// Note that number of partitions and replicas is optional. If they are
	// not specified, the defaults configured on the Kafka brokers will be used
	CreateTopicsResult newTopic = admin.createTopics(Collections.singletonList( new NewTopic(TOPIC_NAME, NUM_PARTITIONS, REP_FACTOR)));

	// Check that the topic was created correctly:
	if (newTopic.numPartitions(TOPIC_NAME).get() != NUM_PARTITIONS) {
		System.out.println("Topic has wrong number of partitions.");
		System.exit(-1);
		}
}
```

Example of ConfigManagement by checking if topic compact configured:

```java
ConfigResource configResource = new ConfigResource(ConfigResource.Type.TOPIC, TOPIC_NAME);

DescribeConfigsResult configsResult = admin.describeConfigs(Collections.singleton(configResource));

Config configs = configsResult.all().get().get(configResource);

// print nondefault configs
configs.entries().stream().filter(entry -> !entry.isDefault() ).forEach(System.out::println);

// Check if topic is compacted
ConfigEntry compaction = new ConfigEntry(
	TopicConfig.CLEANUP_POLICY_CONFIG,
	TopicConfig.CLEANUP_POLICY_COMPACT
);

if (!configs.entries().contains(compaction)) {
	// if topic is not compacted, compact it
	Collection<AlterConfigOp> configOp = new ArrayList<AlterConfigOp>();
	configOp.add(new AlterConfigOp(compaction, AlterConfigOp.OpType.SET));
	Map<ConfigResource, Collection<AlterConfigOp>> alterConf = new HashMap<>();
	alterConf.put(configResource, configOp);
	admin.incrementalAlterConfigs(alterConf).all().get();
} else {
	System.out.println("Topic " + TOPIC_NAME + " is compacted topic");
}
```

Consume group management example:

```java
ConsumerGroupDescription groupDescription = admin
    .describeConsumerGroups(CONSUMER_GRP_LIST)
    .describedGroups().get(CONSUMER_GROUP).get();
System.out.println("Description of group " + CONSUMER_GROUP + ":" + groupDescription);
```

Adding partitions:

```java
Map<String, NewPartitions> newPartitions = new HashMap<>();
newPartitions.put(TOPIC_NAME, NewPartitions.increaseTo(NUM_PARTITIONS+2));
admin.createPartitions(newPartitions).all().get();
```

Deleting records:

```java
Map<TopicPartition, ListOffsetsResult.ListOffsetsResultInfo> olderOffsets = admin.listOffsets(requestOlderOffsets).all().get();

Map<TopicPartition, RecordsToDelete> recordsToDelete = new HashMap<>();
for (Map.Entry<TopicPartition, ListOffsetsResult.ListOffsetsResultInfo>  e: olderOffsets.entrySet()) {
    recordsToDelete.put(
	    e.getKey(),
	    RecordsToDelete.beforeOffset(e.getValue().offset())
	);
}
admin.deleteRecords(recordsToDelete).all().get();
```

Reassigning replicas:

```java
Map<TopicPartition, Optional<NewPartitionReassignment>> reassignment = new HashMap<>();

reassignment.put(
	new TopicPartition(TOPIC_NAME, 0),
    Optional.of(new NewPartitionReassignment(Arrays.asList(0,1)))
);
reassignment.put(
	new TopicPartition(TOPIC_NAME, 1),
	Optional.of(new NewPartitionReassignment(Arrays.asList(1)))
);
reassignment.put(
	new TopicPartition(TOPIC_NAME, 2),
	Optional.of(new NewPartitionReassignment(Arrays.asList(1,0)))
);
reassignment.put(new TopicPartition(TOPIC_NAME, 3), Optional.empty());

admin.alterPartitionReassignments(reassignment).all().get();
System.out.println("currently reassigning: " + admin.listPartitionReassignments().reassignments().get());

demoTopic = admin.describeTopics(TOPIC_LIST);
topicDescription = demoTopic.values().get(TOPIC_NAME).get();
System.out.println("Description of demo topic:" + topicDescription);
```
